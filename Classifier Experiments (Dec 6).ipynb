{
 "metadata": {
  "name": "",
  "signature": "sha256:0362c805bc6f809b374171a2336025b44f75cca4a5a4598eb4ee1a0df8467be2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os, re, json\n",
      "import collections\n",
      "%pylab inline\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_utils\n",
      "reload(data_utils)\n",
      "\n",
      "import analysis\n",
      "reload(analysis)\n",
      "\n",
      "import classifier\n",
      "reload(classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "<module 'classifier' from 'classifier.py'>"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infile = \"data/mturk-prod.train\"\n",
      "df = data_utils.load_annotated(infile)\n",
      "\n",
      "# Restrict to unambiguous labels\n",
      "nunamb = len(df[df.__LABEL__.notnull()])\n",
      "print \"%d unambiguous labels\" % nunamb\n",
      "nsentence = len(df[df.__LABEL_BIN__ == \"-SENTENCE-\"])\n",
      "print \"%d sentences (%.02f%%)\" % (nsentence, 100*nsentence/(1.0*nunamb))\n",
      "\n",
      "df = data_utils.make_basic_features(df)\n",
      "print df.shape\n",
      "for c in df.columns:\n",
      "    print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5306 unambiguous labels\n",
        "1884 sentences (35.51%)\n",
        "(9000, 17)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "__LABEL__\n",
        "__TEXT__\n",
        "lemma\n",
        "ner\n",
        "pos\n",
        "word\n",
        "__LABELS__\n",
        "__LABEL_BIN__\n",
        "f_nchars\n",
        "f_nwords\n",
        "f_npunct\n",
        "f_rpunct\n",
        "f_ndigit\n",
        "f_rdigit\n",
        "f_nner\n",
        "f_rner\n",
        "f_sentence_pattern\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdf = data_utils.get_pos_counts(df)\n",
      "# display(pdf.head())\n",
      "print pdf.columns\n",
      "\n",
      "# Normalize by row\n",
      "pdf_norm = pdf.divide(pdf.sum(axis=0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'f_pos_#', u'f_pos_$', u'f_pos_''', u'f_pos_,', u'f_pos_-LRB-', u'f_pos_-RRB-', u'f_pos_.', u'f_pos_:', u'f_pos_CC', u'f_pos_CD', u'f_pos_DT', u'f_pos_EX', u'f_pos_FW', u'f_pos_IN', u'f_pos_JJ', u'f_pos_JJR', u'f_pos_JJS', u'f_pos_LS', u'f_pos_MD', u'f_pos_NN', u'f_pos_NNP', u'f_pos_NNPS', u'f_pos_NNS', u'f_pos_PDT', u'f_pos_POS', u'f_pos_PRP', u'f_pos_PRP$', u'f_pos_RB', u'f_pos_RBR', u'f_pos_RBS', u'f_pos_RP', u'f_pos_SYM', u'f_pos_TO', u'f_pos_UH', u'f_pos_VB', u'f_pos_VBD', u'f_pos_VBG', u'f_pos_VBN', u'f_pos_VBP', u'f_pos_VBZ', u'f_pos_WDT', u'f_pos_WP', u'f_pos_WP$', u'f_pos_WRB', u'f_pos_``'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CV_N_JOBS = 6\n",
      "\n",
      "# Merge -> all features\n",
      "data = df.merge(pdf_norm, how='outer', left_index=True, right_index=True)\n",
      "\n",
      "X, y, int_to_label, col_to_feature = data_utils.dataframe_to_xy(data, \n",
      "                                                                r\"f_.*\", \n",
      "                                                                label_col=\"__LABEL_BIN__\")\n",
      "from sklearn import preprocessing\n",
      "X = preprocessing.StandardScaler().fit_transform(X)\n",
      "\n",
      "print X.shape\n",
      "print int_to_label\n",
      "print \"Features: \" + \", \".join(col_to_feature.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5306, 54)\n",
        "{0: '-OTHER-', 1: '-SENTENCE-'}\n",
        "Features: f_nchars, f_nwords, f_npunct, f_rpunct, f_ndigit, f_rdigit, f_nner, f_rner, f_sentence_pattern, f_pos_#, f_pos_$, f_pos_'', f_pos_,, f_pos_-LRB-, f_pos_-RRB-, f_pos_., f_pos_:, f_pos_CC, f_pos_CD, f_pos_DT, f_pos_EX, f_pos_FW, f_pos_IN, f_pos_JJ, f_pos_JJR, f_pos_JJS, f_pos_LS, f_pos_MD, f_pos_NN, f_pos_NNP, f_pos_NNPS, f_pos_NNS, f_pos_PDT, f_pos_POS, f_pos_PRP, f_pos_PRP$, f_pos_RB, f_pos_RBR, f_pos_RBS, f_pos_RP, f_pos_SYM, f_pos_TO, f_pos_UH, f_pos_VB, f_pos_VBD, f_pos_VBG, f_pos_VBN, f_pos_VBP, f_pos_VBZ, f_pos_WDT, f_pos_WP, f_pos_WP$, f_pos_WRB, f_pos_``\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Logistic experiment\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression(penalty='l1', C=1000, intercept_scaling=1, \n",
      "                         class_weight='auto')\n",
      "param_grid = [{'C': [0.1,1,10,100,1000], \n",
      "               'penalty':['l1', 'l2']}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'penalty': 'l2', 'C': 1}\n",
        "Best score: 92.14%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5-fold cv:\n",
        " acc: 94.31 +\\- 0.36%\n",
        " pre: 90.46 +\\- 0.82%\n",
        " rec: 93.90 +\\- 0.51%\n",
        "  f1: 92.14 +\\- 0.48%\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Logistic experiment\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression(penalty='l1', C=1000, intercept_scaling=1, \n",
      "                         class_weight='auto')\n",
      "param_grid = [{'C': [0.1,1,10,100,1000], \n",
      "               'penalty':['l1', 'l2']}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression(penalty='l1', C=1000, intercept_scaling=1, \n",
      "                         class_weight='auto')\n",
      "\n",
      "# Grid Search for parameters\n",
      "from sklearn import grid_search\n",
      "param_grid = [{'C': [0.1,1,10,100,1000], \n",
      "               'penalty':['l1', 'l2']}]\n",
      "clfopt = grid_search.GridSearchCV(clf, param_grid, scoring='f1', cv=5, n_jobs=CV_N_JOBS)\n",
      "clfopt.fit(X, y)\n",
      "print \"Best params: \" + str(clfopt.best_params_)\n",
      "print \"Best score: %.02f%%\" % (100*clfopt.best_score_)\n",
      "\n",
      "print \"Best features:\"\n",
      "for l,w in sorted(zip(col_to_feature.values(), clfopt.best_estimator_.coef_[0]),\n",
      "                  key=lambda s: abs(s[1]), reverse=True)[:10]:\n",
      "    print \"%s : %.04f\" % (l.ljust(10),w) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features: f_nchars, f_nwords, f_npunct, f_rpunct, f_ndigit, f_rdigit, f_nner, f_rner, f_sentence_pattern, f_pos_#, f_pos_$, f_pos_'', f_pos_,, f_pos_-LRB-, f_pos_-RRB-, f_pos_., f_pos_:, f_pos_CC, f_pos_CD, f_pos_DT, f_pos_EX, f_pos_FW, f_pos_IN, f_pos_JJ, f_pos_JJR, f_pos_JJS, f_pos_LS, f_pos_MD, f_pos_NN, f_pos_NNP, f_pos_NNPS, f_pos_NNS, f_pos_PDT, f_pos_POS, f_pos_PRP, f_pos_PRP$, f_pos_RB, f_pos_RBR, f_pos_RBS, f_pos_RP, f_pos_SYM, f_pos_TO, f_pos_UH, f_pos_VB, f_pos_VBD, f_pos_VBG, f_pos_VBN, f_pos_VBP, f_pos_VBZ, f_pos_WDT, f_pos_WP, f_pos_WP$, f_pos_WRB, f_pos_``\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'penalty': 'l2', 'C': 1}\n",
        "Best score: 92.14%\n",
        "Best features:\n",
        "f_sentence_pattern : 1.8052\n",
        "f_npunct   : -1.2783\n",
        "f_pos_:    : -0.9162\n",
        "f_pos_.    : 0.8866\n",
        "f_nchars   : -0.7720\n",
        "f_pos_VB   : 0.6718\n",
        "f_ndigit   : -0.5694\n",
        "f_pos_VBZ  : 0.5497\n",
        "f_pos_VBP  : 0.5470\n",
        "f_nner     : 0.3948\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}