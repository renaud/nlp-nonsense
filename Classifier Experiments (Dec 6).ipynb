{
 "metadata": {
  "name": "",
  "signature": "sha256:107aff02d32281db412d64065c9a17d2cc9ffd31efe4d3a5c704a1e6e1f3928e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os, re, json\n",
      "import collections\n",
      "%pylab inline\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_utils\n",
      "reload(data_utils)\n",
      "\n",
      "import analysis\n",
      "reload(analysis)\n",
      "\n",
      "import classifier\n",
      "reload(classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<module 'classifier' from 'classifier.pyc'>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load data and generate features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infile = \"data/mturk-prod.train\"\n",
      "df = data_utils.load_annotated(infile)\n",
      "\n",
      "# Restrict to unambiguous labels\n",
      "nunamb = len(df[df.__LABEL__.notnull()])\n",
      "print \"%d unambiguous labels\" % nunamb\n",
      "nsentence = len(df[df.__LABEL_BIN__ == \"-SENTENCE-\"])\n",
      "print \"%d sentences (%.02f%%)\" % (nsentence, 100*nsentence/(1.0*nunamb))\n",
      "\n",
      "df = data_utils.make_basic_features(df)\n",
      "print df.shape\n",
      "for c in df.columns:\n",
      "    print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5306 unambiguous labels\n",
        "1884 sentences (35.51%)\n",
        "(9000, 19)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "__LABEL__\n",
        "__TEXT__\n",
        "lemma\n",
        "ner\n",
        "pos\n",
        "word\n",
        "__LABELS__\n",
        "__LABEL_BIN__\n",
        "f_nchars\n",
        "f_nwords\n",
        "f_npunct\n",
        "f_rpunct\n",
        "f_ndigit\n",
        "f_rdigit\n",
        "f_nupper\n",
        "f_rupper\n",
        "f_nner\n",
        "f_rner\n",
        "f_sentence_pattern\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate POS features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Distributional\n",
      "pdf = data_utils.get_pos_counts(df)\n",
      "\n",
      "# L1-normalized distributional\n",
      "pdf_norm = pdf.divide(pdf.sum(axis=0))\n",
      "\n",
      "# Positional (begin,end token indicators)\n",
      "ppdf = data_utils.get_pos_positionals(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classifier Experiments\n",
      "Convert to sklearn format, and run preprocessing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CV_N_JOBS = 6\n",
      "\n",
      "# Merge -> all features\n",
      "data = df\n",
      "data = data.merge(pdf_norm, how='outer', left_index=True, right_index=True)\n",
      "data = data.merge(ppdf, how='outer', left_index=True, right_index=True)\n",
      "\n",
      "label_col = \"__LABEL_BIN__\"\n",
      "data = data[data[label_col].notnull()]\n",
      "X, y, int_to_label, col_to_feature = data_utils.dataframe_to_xy(data, \n",
      "                                                                r\"f_.*\", \n",
      "                                                                label_col=label_col)\n",
      "from sklearn import preprocessing\n",
      "X = preprocessing.StandardScaler().fit_transform(X)\n",
      "\n",
      "print X.shape\n",
      "print int_to_label\n",
      "print \"Features: \" + \", \".join(col_to_feature.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5306, 146)\n",
        "{0: '-OTHER-', 1: '-SENTENCE-'}\n",
        "Features: f_nchars, f_nwords, f_npunct, f_rpunct, f_ndigit, f_rdigit, f_nupper, f_rupper, f_nner, f_rner, f_sentence_pattern, f_pos_#, f_pos_$, f_pos_'', f_pos_,, f_pos_-LRB-, f_pos_-RRB-, f_pos_., f_pos_:, f_pos_CC, f_pos_CD, f_pos_DT, f_pos_EX, f_pos_FW, f_pos_IN, f_pos_JJ, f_pos_JJR, f_pos_JJS, f_pos_LS, f_pos_MD, f_pos_NN, f_pos_NNP, f_pos_NNPS, f_pos_NNS, f_pos_PDT, f_pos_POS, f_pos_PRP, f_pos_PRP$, f_pos_RB, f_pos_RBR, f_pos_RBS, f_pos_RP, f_pos_SYM, f_pos_TO, f_pos_UH, f_pos_VB, f_pos_VBD, f_pos_VBG, f_pos_VBN, f_pos_VBP, f_pos_VBZ, f_pos_WDT, f_pos_WP, f_pos_WP$, f_pos_WRB, f_pos_``, f_pos_begin_#, f_pos_begin_$, f_pos_begin_'', f_pos_begin_,, f_pos_begin_-LRB-, f_pos_begin_-RRB-, f_pos_begin_., f_pos_begin_:, f_pos_begin_CC, f_pos_begin_CD, f_pos_begin_DT, f_pos_begin_EX, f_pos_begin_FW, f_pos_begin_IN, f_pos_begin_JJ, f_pos_begin_JJR, f_pos_begin_JJS, f_pos_begin_LS, f_pos_begin_MD, f_pos_begin_NN, f_pos_begin_NNP, f_pos_begin_NNPS, f_pos_begin_NNS, f_pos_begin_PDT, f_pos_begin_POS, f_pos_begin_PRP, f_pos_begin_PRP$, f_pos_begin_RB, f_pos_begin_RBR, f_pos_begin_RBS, f_pos_begin_RP, f_pos_begin_SYM, f_pos_begin_TO, f_pos_begin_UH, f_pos_begin_VB, f_pos_begin_VBD, f_pos_begin_VBG, f_pos_begin_VBN, f_pos_begin_VBP, f_pos_begin_VBZ, f_pos_begin_WDT, f_pos_begin_WP, f_pos_begin_WP$, f_pos_begin_WRB, f_pos_begin_``, f_pos_end_#, f_pos_end_$, f_pos_end_'', f_pos_end_,, f_pos_end_-LRB-, f_pos_end_-RRB-, f_pos_end_., f_pos_end_:, f_pos_end_CC, f_pos_end_CD, f_pos_end_DT, f_pos_end_EX, f_pos_end_FW, f_pos_end_IN, f_pos_end_JJ, f_pos_end_JJR, f_pos_end_JJS, f_pos_end_LS, f_pos_end_MD, f_pos_end_NN, f_pos_end_NNP, f_pos_end_NNPS, f_pos_end_NNS, f_pos_end_PDT, f_pos_end_POS, f_pos_end_PRP, f_pos_end_PRP$, f_pos_end_RB, f_pos_end_RBR, f_pos_end_RBS, f_pos_end_RP, f_pos_end_SYM, f_pos_end_TO, f_pos_end_UH, f_pos_end_VB, f_pos_end_VBD, f_pos_end_VBG, f_pos_end_VBN, f_pos_end_VBP, f_pos_end_VBZ, f_pos_end_WDT, f_pos_end_WP, f_pos_end_WP$, f_pos_end_WRB, f_pos_end_``\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test Classifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Logistic experiment\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "clf = LogisticRegression(penalty='l1', C=1000, intercept_scaling=1, \n",
      "                         class_weight='auto')\n",
      "param_grid = [{'C': [0.1,1,10,100,1000], \n",
      "               'penalty':['l1', 'l2']}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv(eval_train=True)\n",
      "\n",
      "print \"Best features:\"\n",
      "for l,w in sorted(zip(col_to_feature.values(), exp.clfopt.best_estimator_.coef_[0]),\n",
      "                  key=lambda s: abs(s[1]), reverse=True)[:10]:\n",
      "    print \"%s : %.04f\" % (l.ljust(10),w) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'penalty': 'l2', 'C': 100}\n",
        "Best score: 92.20%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "== train sets ==\n",
        "5-fold cv:\n",
        " acc: 95.06 +\\- 0.12%\n",
        " pre: 91.73 +\\- 0.15%\n",
        " rec: 94.61 +\\- 0.19%\n",
        "  f1: 93.15 +\\- 0.16%\n",
        "== test sets ==\n",
        "5-fold cv:\n",
        " acc: 94.36 +\\- 0.31%\n",
        " pre: 90.73 +\\- 0.77%\n",
        " rec: 93.74 +\\- 0.57%\n",
        "  f1: 92.20 +\\- 0.41%\n",
        "Best features:\n",
        "f_nchars   : -1.9858\n",
        "f_npunct   : -1.9003\n",
        "f_sentence_pattern : 1.8831\n",
        "f_pos_:    : -1.0258\n",
        "f_pos_.    : 0.9057\n",
        "f_rupper   : -0.8620\n",
        "f_nupper   : 0.7740\n",
        "f_pos_LS   : -0.7077\n",
        "f_pos_VB   : 0.6773\n",
        "f_pos_VBZ  : 0.6110\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Linear SVM Experiment\n",
      "from sklearn.svm import LinearSVC\n",
      "clf = LinearSVC(penalty='l1', C=1000, intercept_scaling=1, \n",
      "                class_weight='auto', dual=False)\n",
      "param_grid = [{'C': [0.001, 0.01, 0.1,1,10,100,1000], \n",
      "               'penalty':['l1', 'l2']}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv(eval_train=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'penalty': 'l1', 'C': 0.1}\n",
        "Best score: 92.38%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "== train sets ==\n",
        "5-fold cv:\n",
        " acc: 95.02 +\\- 0.07%\n",
        " pre: 91.87 +\\- 0.08%\n",
        " rec: 94.32 +\\- 0.13%\n",
        "  f1: 93.08 +\\- 0.10%\n",
        "== test sets ==\n",
        "5-fold cv:\n",
        " acc: 94.53 +\\- 0.30%\n",
        " pre: 91.27 +\\- 0.62%\n",
        " rec: 93.58 +\\- 0.54%\n",
        "  f1: 92.40 +\\- 0.42%\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Non-linear SVM Experiment\n",
      "from sklearn.svm import SVC\n",
      "clf = SVC(C=1000, class_weight='auto')\n",
      "param_grid = [{'C': [0.1,1,10,100,1000],\n",
      "               'gamma': [0.0, 0.001, 0.01, 0.1],\n",
      "               'kernel': ['rbf']}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv(eval_train=True)\n",
      "\n",
      "# Check support vector size\n",
      "exp.clf.fit(X,y)\n",
      "exp.clf.n_support_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
        "Best score: 92.64%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "== train sets ==\n",
        "5-fold cv:\n",
        " acc: 96.80 +\\- 0.04%\n",
        " pre: 95.07 +\\- 0.12%\n",
        " rec: 95.95 +\\- 0.10%\n",
        "  f1: 95.51 +\\- 0.06%\n",
        "== test sets ==\n",
        "5-fold cv:\n",
        " acc: 94.76 +\\- 0.37%\n",
        " pre: 92.36 +\\- 0.48%\n",
        " rec: 92.94 +\\- 0.76%\n",
        "  f1: 92.64 +\\- 0.52%\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([491, 340], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Random Forest Experiment\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
      "param_grid = [{'n_estimators': [10,50,100,200],\n",
      "               'max_depth': [5,10,20,40]}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv(eval_train=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'n_estimators': 200, 'max_depth': 40}\n",
        "Best score: 94.19%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "== train sets ==\n",
        "5-fold cv:\n",
        " acc: 99.98 +\\- 0.01%\n",
        " pre: 100.00 +\\- 0.00%\n",
        " rec: 99.95 +\\- 0.01%\n",
        "  f1: 99.97 +\\- 0.01%\n",
        "== test sets ==\n",
        "5-fold cv:\n",
        " acc: 95.80 +\\- 0.26%\n",
        " pre: 95.42 +\\- 0.60%\n",
        " rec: 92.62 +\\- 0.72%\n",
        "  f1: 93.99 +\\- 0.39%\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier\n",
      "reload(classifier)\n",
      "\n",
      "# Boosting Experiment\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "clf = AdaBoostClassifier(n_estimators=10)\n",
      "param_grid = [{'n_estimators': [10,50,100,200]}]\n",
      "\n",
      "exp = classifier.ClassifierExperiment(clf, X, y)\n",
      "exp.grid_search(param_grid, scoring='f1')\n",
      "res, stats = exp.eval_cv(eval_train=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best params: {'n_estimators': 200}\n",
        "Best score: 92.82%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "== train sets ==\n",
        "5-fold cv:\n",
        " acc: 96.58 +\\- 0.07%\n",
        " pre: 95.34 +\\- 0.14%\n",
        " rec: 95.02 +\\- 0.21%\n",
        "  f1: 95.18 +\\- 0.10%\n",
        "== test sets ==\n",
        "5-fold cv:\n",
        " acc: 94.91 +\\- 0.20%\n",
        " pre: 93.00 +\\- 0.72%\n",
        " rec: 92.68 +\\- 0.89%\n",
        "  f1: 92.82 +\\- 0.30%\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}